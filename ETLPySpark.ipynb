{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Подготовка среды"
      ],
      "metadata": {
        "id": "xWsNrN_p2ARl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка pyspark"
      ],
      "metadata": {
        "id": "Owb93u6Y1UzW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r0TeUMa1H3D",
        "outputId": "1219ab08-55d9-4628-9e9b-f5dcfc510f3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установим драйвер JDBC для БД SQLite"
      ],
      "metadata": {
        "id": "jY4KpFRF1azf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O sqlite-jdbc.jar https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.41.2.1/sqlite-jdbc-3.41.2.1.jar"
      ],
      "metadata": {
        "id": "WzhAjgcE1ru9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем SparkSession для ETL-проекта и настраиваем подключение к SQLite через JDBC"
      ],
      "metadata": {
        "id": "oEnyqVuFe8Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "import sqlite3\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FinanceETL\") \\\n",
        "    .config(\"spark.driver.extraClassPath\", \"sqlite-jdbc.jar\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "kwmO3WOk1wdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Извлечение данных\n"
      ],
      "metadata": {
        "id": "AGL757df_E9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем SparkSession.read API для загрузки данных из CSV:"
      ],
      "metadata": {
        "id": "zwk6xI8j_Jok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stocks = spark.read.csv(\"major-tech-stock-2019-2024.csv\", header=True, inferSchema=True)\n",
        "df_stocks.printSchema()\n",
        "df_stocks.show(5)"
      ],
      "metadata": {
        "id": "TkfNuMFL196C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135f5476-d66e-4831-de23-b8b3f2cb3b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Ticker: string (nullable = true)\n",
            "\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+\n",
            "|      Date|              Open|              High|               Low|             Close|         Adj Close|   Volume|Ticker|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+\n",
            "|2019-01-02| 38.72249984741211|39.712501525878906|38.557498931884766| 39.47999954223633|37.793785095214844|148158800|  AAPL|\n",
            "|2019-01-03|35.994998931884766| 36.43000030517578|              35.5| 35.54750061035156| 34.02924346923828|365248800|  AAPL|\n",
            "|2019-01-04| 36.13249969482422| 37.13750076293945| 35.95000076293945|37.064998626708984| 35.48192596435547|234428400|  AAPL|\n",
            "|2019-01-07| 37.17499923706055| 37.20750045776367|36.474998474121094| 36.98249816894531|35.402950286865234|219111200|  AAPL|\n",
            "|2019-01-08| 37.38999938964844| 37.95500183105469|37.130001068115234|           37.6875| 36.07784652709961|164101200|  AAPL|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь извлечем данные из таблицы companies в SQLite. Spark предоставляет возможность читать из СУБД через формат jdbc:"
      ],
      "metadata": {
        "id": "19NYiZXX_VR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_companies = spark.read.format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:companies_db.sqlite\") \\\n",
        "    .option(\"dbtable\", \"companies\") \\\n",
        "    .option(\"driver\", \"org.sqlite.JDBC\") \\\n",
        "    .load()\n",
        "\n",
        "df_companies.printSchema()\n",
        "df_companies.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcxEaS-h_UtF",
        "outputId": "c674fff1-4736-4425-ec30-bcfc611a795a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Symbol: string (nullable = true)\n",
            " |-- CompanyName: string (nullable = true)\n",
            " |-- Sector: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+------+--------------------+--------------------+-------+\n",
            "|Symbol|         CompanyName|              Sector|Country|\n",
            "+------+--------------------+--------------------+-------+\n",
            "|  AAPL|          Apple Inc.|          Technology|    USA|\n",
            "|  MSFT|Microsoft Corpora...|          Technology|    USA|\n",
            "|  AMZN|    Amazon.com, Inc.|Consumer Discreti...|    USA|\n",
            "| GOOGL|       Alphabet Inc.|Communication Ser...|    USA|\n",
            "|  TSLA|         Tesla, Inc.|Consumer Discreti...|    USA|\n",
            "+------+--------------------+--------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Объединение данных и проверки"
      ],
      "metadata": {
        "id": "cygpUKaI_cEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_stocks.join(df_companies, # То с чем объединяем\n",
        "                           df_stocks[\"Ticker\"] == df_companies[\"Symbol\"], # Условие объединения\n",
        "                           how=\"inner\") # Тип объединения\n",
        "df_joined.printSchema()\n",
        "df_joined = df_joined.drop(\"Ticker\")# Удалим дублёр\n",
        "df_joined.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CJMcP68_YiF",
        "outputId": "fbc23274-1a7f-42fc-f351-574218b05779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Ticker: string (nullable = true)\n",
            " |-- Symbol: string (nullable = true)\n",
            " |-- CompanyName: string (nullable = true)\n",
            " |-- Sector: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+--------+------+-----------+----------+-------+\n",
            "|      Date|              Open|              High|               Low|             Close|         Adj Close|  Volume|Symbol|CompanyName|    Sector|Country|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+--------+------+-----------+----------+-------+\n",
            "|2023-12-29|193.89999389648438|194.39999389648438|191.72999572753906|192.52999877929688|192.02418518066406|42628800|  AAPL| Apple Inc.|Technology|    USA|\n",
            "|2023-12-28|194.13999938964844|194.66000366210938| 193.1699981689453| 193.5800018310547|193.07142639160156|34049900|  AAPL| Apple Inc.|Technology|    USA|\n",
            "|2023-12-27|192.49000549316406|             193.5|191.08999633789062|193.14999389648438|192.64254760742188|48087700|  AAPL| Apple Inc.|Technology|    USA|\n",
            "|2023-12-26|193.61000061035156|193.88999938964844| 192.8300018310547| 193.0500030517578|192.54281616210938|28919300|  AAPL| Apple Inc.|Technology|    USA|\n",
            "|2023-12-22|195.17999267578125|195.41000366210938|192.97000122070312|193.60000610351562| 193.0913848876953|37122800|  AAPL| Apple Inc.|Technology|    USA|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+--------+------+-----------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Очистка и преобразование данных"
      ],
      "metadata": {
        "id": "2kU6Img-ACnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Проверка и обработка пропущенных значений."
      ],
      "metadata": {
        "id": "NxwNJzm2AKeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df_joined.select(\n",
        "    [F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
        "    for c in df_joined.columns])\n",
        "null_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbzW5uUiAH3w",
        "outputId": "ecf27a7f-0d12-4ed4-846a-da630f4e5019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+---+-----+---------+------+------+------+-----------+------+-------+\n",
            "|Date|Open|High|Low|Close|Adj Close|Volume|Ticker|Symbol|CompanyName|Sector|Country|\n",
            "+----+----+----+---+-----+---------+------+------+------+-----------+------+-------+\n",
            "|   0|   0|   0|  0|    0|        0|     0|     0|     0|          0|     0|      0|\n",
            "+----+----+----+---+-----+---------+------+------+------+-----------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Стратегии обработки пропусков:**\n",
        "\n",
        "\n",
        "*   Если пропусков мало и они в несущественных строках – данные можно удалить. В PySpark: df_drop = df_joined.na.drop(subset=[\"ColumnName1\",\"ColumnName2\"]) – удалит строки, где любое из\n",
        "указанных полей пустое. Либо .drop() без параметров – удалит любую строку, где какой-либо столбец пустой.\n",
        "*   **Заполнение значениями:** метод df.fillna(value, subset=[\"col1\",\"col2\"]) или эквивалент df.na.fill(). Можно подставить фиксированное значение. Например, если в секторе у компании стоит null, можно заменить на \"Unknown\"; если пропущен объем – можно поставить 0 (или среднее значение, но для простоты 0).\n",
        "\n",
        "*   Более сложные подходы: вычислить среднее/медиану и заполнить, использовать forward fill (протягивание предыдущего значения по дате, актуально для временных рядов), но эти методы требуют дополнительной логики.\n",
        "\n"
      ],
      "metadata": {
        "id": "i48HRme_BL-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для примера применим комбинацию: удалим записи без объема (считаем, что объем критически важен), а категориальные пропуски, если бы были, заменим на \"Unknown\"."
      ],
      "metadata": {
        "id": "Z1l_dPjYBtbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_joined.na.drop(subset=[\"Volume\"])\n",
        "df_joined = df_joined.fillna({\"Sector\": \"Unknown\"})"
      ],
      "metadata": {
        "id": "gKP3fP20BDLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Преобразование типов данных."
      ],
      "metadata": {
        "id": "X3jo1CyMB1UQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " В нашем датафрейме Date сейчас представлена как строка (формат \"yyyy-MM-dd\"). Для удобства агрегирования по датам можно преобразовать ее в тип DateType. Spark предоставляет функцию to_date:\\"
      ],
      "metadata": {
        "id": "61y88cdKB5B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_joined.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n",
        "df_joined.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq9Zk0VJB-C5",
        "outputId": "8c69b110-02bb-43e4-cc1f-b34f7dae7e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Symbol: string (nullable = true)\n",
            " |-- CompanyName: string (nullable = true)\n",
            " |-- Sector: string (nullable = false)\n",
            " |-- Country: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь столбец Date станет типа date. Также можем выделить из даты дополнительные атрибуты, если понадобится, например год или месяц:"
      ],
      "metadata": {
        "id": "m1WsBZ8ZB_CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined = df_joined.withColumn(\n",
        "    \"Year\", F.year(\"Date\")).withColumn(\"Month\", F.month(\"Date\"))\n",
        "df_joined.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9u8oHfcB52P",
        "outputId": "77f4a338-cb9a-4c42-965e-d7a82d2b59de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Symbol: string (nullable = true)\n",
            " |-- CompanyName: string (nullable = true)\n",
            " |-- Sector: string (nullable = false)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это добавит два новых столбца: год и месяц, извлеченные из даты."
      ],
      "metadata": {
        "id": "H6BZZSmlCReB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Другие преобразования типов, которые могут понадобиться:\n",
        "\n",
        "\n",
        "*   Приведение строковых чисел к числовым типам\n",
        "`(df.withColumn(\"col_new\", df.col_old.cast(\"integer\")))`.\n",
        "*   Разбиение составных полей, объединение полей (конкатенация строк).\n",
        "*   Например, можно объединить столбцы Name и Sector в одно поле или наоборот, разнести сектор на более общую категорию (в данном случае нет необходимости, просто отмечаем возможности).\n",
        "\n"
      ],
      "metadata": {
        "id": "Eo5kY-odCsCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, мы выполнили все шаги очистки и преобразования: устранили пропуски, привели типы данных, добавили нужные столбцы. Теперь перейдем к аналитическим операциям – агрегациям и фильтрации, т.е. собственно к анализу данных."
      ],
      "metadata": {
        "id": "RSo5147QDDyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Агрегация данных"
      ],
      "metadata": {
        "id": "J7HPC8IdDFAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для демонстрации возможностей Spark по агрегированию данных придумаем несколько задач:"
      ],
      "metadata": {
        "id": "pChU58ftHN10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1 Средняя цена закрытия по каждому тикеру** (Symbol). Используем groupBy и avg:"
      ],
      "metadata": {
        "id": "eakeR1eDHWHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_close_by_symbol = df_joined.groupBy(\"Symbol\").agg(F.avg(\"Close\").alias(\"AvgClose\"))\n",
        "avg_close_by_symbol.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqneuWcqHYA-",
        "outputId": "dd820617-c264-4b4e-ad14-5c95013cf229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|Symbol|          AvgClose|\n",
            "+------+------------------+\n",
            "|  AAPL| 123.0310850674094|\n",
            "|  TSLA|  170.887469464531|\n",
            "| GOOGL| 98.19300560276535|\n",
            "|  AMZN|127.64970470119167|\n",
            "|  MSFT| 236.2598490146461|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Суммарный объем и количество дней по годам для каждой компании.** Здесь сгруппируем по двум полям: Symbol и Year. В агрегатах посчитаем сумму Volume и количество записей. Spark имеет функцию count, а сумму – sum."
      ],
      "metadata": {
        "id": "0eTqb-AGHfzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats_by_year = df_joined.groupBy(\"Symbol\",\"Year\").agg(\n",
        "        F.count(\"*\").alias(\"DaysCount\"),\n",
        "        F.sum(\"Volume\").alias(\"TotalVolume\")\n",
        "        ).orderBy(\"Symbol\",\"Year\")\n",
        "stats_by_year.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xja_lE2JHfGF",
        "outputId": "e3558740-fe16-4763-e8af-1a37f595022e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+---------+-----------+\n",
            "|Symbol|Year|DaysCount|TotalVolume|\n",
            "+------+----+---------+-----------+\n",
            "|  AAPL|2019|      252|28254942800|\n",
            "|  AAPL|2020|      253|39863855600|\n",
            "|  AAPL|2021|      252|22812206100|\n",
            "|  AAPL|2022|      251|22065504500|\n",
            "|  AAPL|2023|      250|14804257200|\n",
            "|  AMZN|2019|      252|19493002000|\n",
            "|  AMZN|2020|      253|24950814000|\n",
            "|  AMZN|2021|      252|17076362000|\n",
            "|  AMZN|2022|      251|19096256300|\n",
            "|  AMZN|2023|      250|14707898000|\n",
            "+------+----+---------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Фильтрация и поиск данных"
      ],
      "metadata": {
        "id": "m1Gio8YcH2LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В Spark можно легко отфильтровать данные по условиям, аналогичным WHERE в SQL. Мы покажем несколько примеров фильтрации на нашем DataFrame df_joined (или на агрегированных результатах):"
      ],
      "metadata": {
        "id": "4QhqdeQeH5Rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример 1:** Фильтрация по значению числового поля. Найдем все записи, где цена закрытия акции превысила определенный порог, скажем $1000 (значимо для акций с высокой ценой, таких как Google или Amazon в некоторые периоды)."
      ],
      "metadata": {
        "id": "lNd_MPGJIAEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expensive_days = df_joined.filter(df_joined.Close > 1000)\n",
        "expensive_days.select(\"Date\",\"Symbol\",\"Close\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pemqMeaEH6zt",
        "outputId": "4dcb89ee-705b-46ee-f1df-8d906309c54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+-----+\n",
            "|Date|Symbol|Close|\n",
            "+----+------+-----+\n",
            "+----+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример 2:** Фильтрация по текстовому полю (строке). Допустим, хотим получить все записи для компании Apple (тикер AAPL)."
      ],
      "metadata": {
        "id": "HUryeTQVIHHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_df = df_joined.filter(df_joined.Symbol == \"AAPL\")\n",
        "apple_df.orderBy(\"Date\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Wc-TVEILLH",
        "outputId": "7b95bb63-d591-4000-9128-0288f5848bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+-----------+----------+-------+----+-----+\n",
            "|      Date|              Open|              High|               Low|             Close|         Adj Close|   Volume|Symbol|CompanyName|    Sector|Country|Year|Month|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+-----------+----------+-------+----+-----+\n",
            "|2019-01-02| 38.72249984741211|39.712501525878906|38.557498931884766| 39.47999954223633|37.793785095214844|148158800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-03|35.994998931884766| 36.43000030517578|              35.5| 35.54750061035156| 34.02924346923828|365248800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-04| 36.13249969482422| 37.13750076293945| 35.95000076293945|37.064998626708984| 35.48192596435547|234428400|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-07| 37.17499923706055| 37.20750045776367|36.474998474121094| 36.98249816894531|35.402950286865234|219111200|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-08| 37.38999938964844| 37.95500183105469|37.130001068115234|           37.6875| 36.07784652709961|164101200|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-09|  37.8224983215332| 38.63249969482422|37.407501220703125| 38.32749938964844| 36.69050216674805|180396400|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-10|            38.125| 38.49250030517578| 37.71500015258789| 38.45000076293945|36.807777404785156|143122800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-11|38.220001220703125| 38.42499923706055|37.877498626708984|  38.0724983215332|36.446388244628906|108092800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-14|37.712501525878906|37.817501068115234| 37.30500030517578|              37.5|35.898345947265625|129756800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-15|37.567501068115234| 38.34749984741211| 37.51250076293945| 38.26750183105469| 36.63307571411133|114843600|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-16| 38.27000045776367|38.970001220703125|             38.25| 38.73500061035156| 37.08060073852539|122278800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-17| 38.54999923706055|39.415000915527344|38.314998626708984| 38.96500015258789| 37.30077362060547|119284800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-18|            39.375|39.470001220703125|38.994998931884766| 39.20500183105469|   37.530517578125|135004000|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-22|39.102500915527344|39.182498931884766|38.154998779296875| 38.32500076293945|  36.6881103515625|121576000|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-23|38.537498474121094| 38.78499984741211| 37.92499923706055| 38.47999954223633|36.836483001708984| 92522400|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-24| 38.52750015258789|38.619998931884766|37.935001373291016| 38.17499923706055| 36.54450988769531|101766000|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-25|38.869998931884766|39.532501220703125| 38.58000183105469|39.439998626708984|  37.7554817199707|134142000|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-28|  38.9474983215332| 39.08250045776367|38.415000915527344| 39.07500076293945|37.406070709228516|104768400|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-29|           39.0625|39.532501220703125| 38.52750015258789| 38.66999816894531| 37.01837158203125|166348800|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "|2019-01-30|           40.8125|41.537498474121094|40.057498931884766|           41.3125|39.548011779785156|244439200|  AAPL| Apple Inc.|Technology|    USA|2019|    1|\n",
            "+----------+------------------+------------------+------------------+------------------+------------------+---------+------+-----------+----------+-------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример 3:** Фильтрация по дате или диапазону дат. Предположим, нужно взять данные за 2020 год для Amazon."
      ],
      "metadata": {
        "id": "aAe4EMeeIZfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_2020 = df_joined.filter((df_joined.Symbol == \"AMZN\") &\n",
        " (F.year(\"Date\") == 2020))\n",
        "amazon_2020.select(\"Date\",\"Close\",\"Volume\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCrbOKTqIYl6",
        "outputId": "bb6438f6-9f40-4e59-cf1b-97824030c17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+\n",
            "|      Date|             Close|   Volume|\n",
            "+----------+------------------+---------+\n",
            "|2020-12-31|162.84649658203125| 59144000|\n",
            "|2020-12-30|164.29249572753906| 64186000|\n",
            "|2020-12-29|166.10000610351562| 97458000|\n",
            "|2020-12-28|  164.197998046875|113736000|\n",
            "|2020-12-24|158.63450622558594| 29038000|\n",
            "+----------+------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример 4:** Поиск по подстроке. Представим, что нужно найти компании, название которых содержит слово \"Inc\". Это скорее опрос справочной таблицы компаний:"
      ],
      "metadata": {
        "id": "aJW9EzUlIwed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_companies.filter(df_companies.CompanyName.contains(\"Inc\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKLYcW64I09B",
        "outputId": "ce339761-c63e-42d6-dfa2-26bbbbf90a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+--------------------+-------+\n",
            "|Symbol|     CompanyName|              Sector|Country|\n",
            "+------+----------------+--------------------+-------+\n",
            "|  AAPL|      Apple Inc.|          Technology|    USA|\n",
            "|  AMZN|Amazon.com, Inc.|Consumer Discreti...|    USA|\n",
            "| GOOGL|   Alphabet Inc.|Communication Ser...|    USA|\n",
            "|  TSLA|     Tesla, Inc.|Consumer Discreti...|    USA|\n",
            "+------+----------------+--------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фильтрация – очень распространенная операция при анализе данных. В контексте ETL ее применяют и на этапе Transform (например, отфильтровать нерелевантные данные, как мы делали при очистке, удаляя строки с null, или исключая дубли). Здесь же мы демонстрируем ее для решения \"поисковых\" задач, когда из объединенного набора данных нужно выбрать интересующую информацию.\n",
        "После выполнения фильтраций, убедитесь, что результаты соответствуют ожиданиям (правильное количество строк, корректные значения). Если нужно, можно также сочетать сортировку (orderBy) и ограничение вывода (limit) для удобства просмотра."
      ],
      "metadata": {
        "id": "VEZ38lQiI9uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Загрузка результатов (Load) в хранилище"
      ],
      "metadata": {
        "id": "6gmv7gFzI_RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Финальный шаг – сохранить полученные данные. Предположим, по результатам наших преобразований мы хотим сформировать итоговый набор данных – например, очищенные и обогащенные данные о ценах акций, готовые для дальнейшего использования или передачи аналитикам. Мы покажем два способа загрузки: в файловую систему (формат Parquet) и обратно в базу данных."
      ],
      "metadata": {
        "id": "46O8Ch_jJDf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.1 Сохранение DataFrame в файл Parquet.**\\\n",
        "Формат Parquet – это эффективный колонковый формат хранения данных, часто используемый в хранилищах big data. Он сохраняет схему и сжатые данные, оптимизирован для последующего чтения Spark'ом и другими инструментами."
      ],
      "metadata": {
        "id": "l7l6GnRUJEoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined.write.mode(\"overwrite\"\n",
        "#мод overwrite использован на случай,\n",
        "#если вы будете несколько раз запускать ячейку\n",
        "#и спарк спокойно переписывал данные\n",
        ").parquet(\"output/stock_data_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "Ag7cmNVfJKzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После выполнения этой команды в директории `output/stock_data_cleaned.parquet` (либо указанной вами) появится набор файлов Parquet, которые представляют разделы датасета."
      ],
      "metadata": {
        "id": "hPPNLm-CJTbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2 Загрузка данных в базу через JDBC**.\\\n",
        "Аналогично тому, как мы читали таблицу через JDBC, можно и записать DataFrame в таблицу базы данных. Предположим, мы хотим записать итоговый объединенный и очищенный набор цен акций в новую таблицу, скажем stock_prices_cleaned в нашей SQLite базе finance.db. Мы можем использовать метод write с форматом jdbc:"
      ],
      "metadata": {
        "id": "R7uSwvojJyJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_joined.write.format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:sqlite:finance.db\") \\\n",
        "    .option(\"dbtable\", \"stock_prices_cleaned\") \\\n",
        "    .option(\"driver\", \"org.sqlite.JDBC\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .save()"
      ],
      "metadata": {
        "id": "5o1e5OIuJ1U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для проверки можно подключиться к БД и посмотреть корреткность сохраненных данных"
      ],
      "metadata": {
        "id": "2JMePmhLKGJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "conn = sqlite3.connect(\"finance.db\")\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"SELECT Symbol, Date, Close, Sector FROM stock_prices_cleaned LIMIT 5;\")\n",
        "rows = cur.fetchall()\n",
        "for r in rows:\n",
        "    print(r)\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t14LNkp0KEVL",
        "outputId": "ddb24957-b086-40ac-be61-19c4e16ee56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('AAPL', 1703808000000, 192.52999877929688, 'Technology')\n",
            "('AAPL', 1703721600000, 193.5800018310547, 'Technology')\n",
            "('AAPL', 1703635200000, 193.14999389648438, 'Technology')\n",
            "('AAPL', 1703548800000, 193.0500030517578, 'Technology')\n",
            "('AAPL', 1703203200000, 193.60000610351562, 'Technology')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задания для закрепления"
      ],
      "metadata": {
        "id": "CvyRcY40KVxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте усложнить ETL-пайплайн:\n"
      ],
      "metadata": {
        "id": "ZeyZMYKXKVJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Добавьте данные о курсе рубля и расчитайте цены в рублях\n",
        "`USD_RUB Historical Data.csv`"
      ],
      "metadata": {
        "id": "MS9OSnluMtOL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRVrzNUrMsNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Определите, в какие месяцы курс доллара был наиболее выгодным для покупки акций."
      ],
      "metadata": {
        "id": "buuyDFZTNIfk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sN5W5esrNVlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Сохраните данные с рублевыми ценами для дальнейшего использования."
      ],
      "metadata": {
        "id": "ZsoZv5JVNULe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BisMtTSzNW1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. загрузите данные из parquet и выведите топ 5 самых дорогих акций в рублях"
      ],
      "metadata": {
        "id": "Q7I_lpYyYaKS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjbaTHFKYc6M"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}